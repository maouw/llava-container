Bootstrap: docker
From: mambaorg/micromamba:{{ MICROMAMBA_TAG }}

%arguments
	MICROMAMBA_TAG=jammy
	PYTHON_VERSION=3.11
	LLAVA_URL=https://codeload.github.com/haotian-liu/LLaVA/tar.gz/refs/heads/main


%files
	../llava-run.py /opt/local/bin/llava-run
	../runscript.help /.singularity.d/runscript.help
	../hyak-llava-web /opt/local/bin/hyak-llava-web

%post
	set -ex
	
	# Set up the micromamba base environment, using requests to download LLaVA:
	micromamba install -y -n base -c conda-forge curl
    
    micromamba create -y -n llava -c conda-forge python={{ PYTHON_VERSION }} pip

	# Download and install LLaVA:
	mkdir -p /opt/setup/llava && cd /opt/setup/llava
    curl -fsSL "{{ LLAVA_URL }}" -o llava.tar.gz
	tar -xzf llava.tar.gz --strip-components=1
	
	# Update pyproject.toml to include the package data in examples (web server breaks without):
	printf '[tool.setuptools.package-data]\nllava = ["serve/examples/*.jpg"]' >>pyproject.toml
	
	# Install LLaVA dependencies:
	micromamba run -n base python -m pip install --no-cache-dir -r /opt/setup/requirements.txt
	
	# Install LLaVA:
	micromamba run -n base python -m pip install --no-cache-dir --config-settings="--install-data=$PWD/llava" .
	
	# Clean up:
	micromamba run -n base python -m pip cache purge
	micromamba clean --all --yes
	rm -rf /opt/setup

%environment
	export MAMBA_DOCKERFILE_ACTIVATE=1
    export ENV_NAME=llava
	export PATH="/opt/local/bin:${PATH}"

%runscript
	# Run the provided command with the micromamba base environment activated:
	eval "$(micromamba shell hook --shell posix)"
	micromamba activate llava
    if [ -n "${HUGGINGFACE_HUB_CACHE:-}" ]; then
        echo "Using HUGGINGFACE_HUB_CACHE=\"${HUGGINGFACE_HUB_CACHE:-}\"" >&2
    else
        echo "HUGGINGFACE_HUB_CACHE not set!" >&2
    fi
	exec "$@"

